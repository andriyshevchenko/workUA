"""–¢–µ—Å—Ç –ø—Ä–æ—Ü–µ—Å—É –≤—ñ–¥–≥—É–∫—É –Ω–∞ –≤–∞–∫–∞–Ω—Å—ñ—é"""
import asyncio
from scraper import WorkUAScraper, JobListing
from config import config


async def test_apply_workflow():
    """–¢–µ—Å—Ç—É—î–º–æ –ø–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –≤—ñ–¥–≥—É–∫—É –Ω–∞ –≤–∞–∫–∞–Ω—Å—ñ—é"""
    
    scraper = WorkUAScraper()
    await scraper.start(headless=False)
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó
    is_logged_in = await scraper.check_login_status()
    print(f"\n{'='*60}")
    print(f"–°—Ç–∞—Ç—É—Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó: {'‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ' if is_logged_in else '‚ùå –ù–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ'}")
    print(f"{'='*60}\n")
    
    if not is_logged_in:
        print("‚ö†Ô∏è –ü–æ—Ç—Ä—ñ–±–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è. –ó–∞–ø—É—Å—Ç—ñ—Ç—å explorer.py —Å–ø–æ—á–∞—Ç–∫—É.")
        await scraper.close()
        return
    
    # –®—É–∫–∞—î–º–æ remote –≤–∞–∫–∞–Ω—Å—ñ—ó
    print("üîç –ü–æ—à—É–∫ –¥–∏—Å—Ç–∞–Ω—Ü—ñ–π–Ω–∏—Ö –≤–∞–∫–∞–Ω—Å—ñ–π...\n")
    jobs = await scraper.search_jobs(
        keyword="python developer",
        remote=True,
        max_pages=1
    )
    
    if not jobs:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å—ñ–π")
        await scraper.close()
        return
    
    # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à—É –≤–∞–∫–∞–Ω—Å—ñ—é –¥–ª—è —Ç–µ—Å—Ç—É
    test_job = jobs[0]
    print(f"\n{'='*60}")
    print(f"üìã –¢–µ—Å—Ç–æ–≤–∞ –≤–∞–∫–∞–Ω—Å—ñ—è:")
    print(f"   –ù–∞–∑–≤–∞: {test_job.title}")
    print(f"   –ö–æ–º–ø–∞–Ω—ñ—è: {test_job.company}")
    print(f"   –õ–æ–∫–∞—Ü—ñ—è: {test_job.location}")
    print(f"   URL: {test_job.url}")
    print(f"{'='*60}\n")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–µ—Ç–∞–ª—ñ
    print("üìÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–µ—Ç–∞–ª–µ–π –≤–∞–∫–∞–Ω—Å—ñ—ó...\n")
    test_job = await scraper.get_job_details(test_job)
    
    # –ü–æ–∫–∞–∑—É—î–º–æ —á–∞—Å—Ç–∏–Ω—É –æ–ø–∏—Å—É
    if test_job.description:
        desc_preview = test_job.description[:200] + "..."
        print(f"üìù –û–ø–∏—Å (–ø–µ—Ä—à—ñ 200 —Å–∏–º–≤–æ–ª—ñ–≤):\n{desc_preview}\n")
    
    # –ü–∏—Ç–∞—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —á–∏ –≤—ñ–¥–≥—É–∫—É–≤–∞—Ç–∏—Å—è
    print(f"{'='*60}")
    response = input("‚ùì –í—ñ–¥–≥—É–∫–Ω—É—Ç–∏—Å—è –Ω–∞ —Ü—é –≤–∞–∫–∞–Ω—Å—ñ—é? (y/n): ")
    print(f"{'='*60}\n")
    
    if response.lower() == 'y':
        print("üöÄ –ü–æ—á–∏–Ω–∞—î–º–æ –ø—Ä–æ—Ü–µ—Å –≤—ñ–¥–≥—É–∫—É...\n")
        success = await scraper.apply_to_job(test_job)
        
        if success:
            print(f"\n{'='*60}")
            print("üéâ –¢–ï–°–¢ –£–°–ü–Ü–®–ù–ò–ô! –í—ñ–¥–≥—É–∫ –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ!")
            print(f"{'='*60}\n")
        else:
            print(f"\n{'='*60}")
            print("‚ùå –¢–ï–°–¢ –ü–†–û–í–ê–õ–ï–ù–ò–ô! –ù–µ –≤–¥–∞–ª–æ—Å—å –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ –≤—ñ–¥–≥—É–∫")
            print(f"{'='*60}\n")
    else:
        print("‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –≤—ñ–¥–≥—É–∫ (—Ç–µ—Å—Ç –Ω–µ –≤–∏–∫–æ–Ω–∞–Ω–æ)\n")
    
    # –ß–µ–∫–∞—î–º–æ —Ç—Ä–æ—Ö–∏ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä–∏—Ç—Ç—è–º —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("‚è≥ –ß–µ–∫–∞—î–º–æ 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä–∏—Ç—Ç—è–º...")
    await asyncio.sleep(5)
    
    await scraper.close()
    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


if __name__ == "__main__":
    asyncio.run(test_apply_workflow())
