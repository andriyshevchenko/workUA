"""–ü—Ä–æ—Å—Ç–∏–π –±–æ—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –≤—ñ–¥–≥—É–∫—É –Ω–∞ –≤–∞–∫–∞–Ω—Å—ñ—ó Work.ua"""

import asyncio
import logging
from typing import List, Tuple

from scraper import WorkUAScraper, JobListing
from config import config
from logging_config import setup_logging
from llm_service import LLMAnalysisService


class WorkUABot:
    """–ë–æ—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –≤—ñ–¥–≥—É–∫—É –Ω–∞ –≤–∞–∫–∞–Ω—Å—ñ—ó"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.scraper = None
        self.llm_service = LLMAnalysisService()

        # Load filter only if LLM features are enabled
        if self.llm_service.use_llm:
            self.llm_service.load_filter()

    async def analyze_job(self, job: JobListing) -> Tuple[bool, int, str]:
        """–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –≤–∞–∫–∞–Ω—Å—ñ—é

        Returns:
            (should_apply, score, reason)
        """
        return self.llm_service.analyze_job(
            job.title, job.company, job.location, job.salary, job.description
        )

    async def run(self, max_applications: int = 10):
        """–ó–∞–ø—É—Å—Ç–∏—Ç–∏ –±–æ—Ç"""
        self._log_header()

        # Initialize scraper
        self.scraper = WorkUAScraper()
        await self.scraper.start(headless=config.HEADLESS)

        # Check authorization
        if not await self._check_authorization():
            return

        # Get search configuration
        search_config = self._get_search_config(max_applications)
        self._log_search_config(search_config)

        # Initialize counters
        stats = {"scanned": 0, "applied": 0, "skipped": 0}

        try:
            # Get all jobs
            jobs = await self._search_jobs(search_config)

            if not jobs:
                self.logger.warning("‚ö†Ô∏è –í–∞–∫–∞–Ω—Å—ñ–π –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                return

            self.logger.info(f"üìã –ó–Ω–∞–π–¥–µ–Ω–æ {len(jobs)} –≤–∞–∫–∞–Ω—Å—ñ–π –∑–∞–≥–∞–ª–æ–º")

            # Process each job
            await self._process_jobs(jobs, max_applications, search_config["max_vacancies"], stats)

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
            import traceback

            self.logger.error(traceback.format_exc())

        finally:
            self._log_final_stats(stats)
            await self.scraper.close()
            self.logger.info("üëã –ó–∞–≤–µ—Ä—à–µ–Ω–æ!")

    def _log_header(self):
        """Log the bot header"""
        self.logger.info("=" * 70)
        self.logger.info("ü§ñ WORK.UA BOT - –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫ —Ä–æ–±–æ—Ç–∏")
        self.logger.info("=" * 70)

    async def _check_authorization(self) -> bool:
        """Check if user is authorized

        Returns:
            True if authorized, False otherwise
        """
        if not self.scraper.is_logged_in:
            is_logged_in = await self.scraper.check_login_status()
            if not is_logged_in:
                self.logger.error("‚ùå –ù–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ! –î–æ–¥–∞–π—Ç–µ WORKUA_PHONE –≤ .env")
                # Don't close here - let run() handle cleanup in finally block
                return False

        self.logger.info("‚úÖ –ê–≤—Ç–æ—Ä—ñ–∑–∞—Ü—ñ—è —É—Å–ø—ñ—à–Ω–∞")
        return True

    def _get_search_config(self, max_applications: int) -> dict:
        """Get search configuration

        Args:
            max_applications: Maximum number of applications

        Returns:
            Dictionary with search configuration
        """
        return {
            "keywords": config.SEARCH_KEYWORDS,
            "remote_only": config.REMOTE_ONLY,
            "locations": config.LOCATIONS if not config.REMOTE_ONLY else [],
            "max_applications": max_applications,
            "max_vacancies": config.MAX_VACANCIES,
            "max_pages": 50,
            "target_jobs": max_applications * config.VACANCY_MULTIPLIER,
        }

    def _log_search_config(self, search_config: dict):
        """Log search configuration

        Args:
            search_config: Search configuration dictionary
        """
        keywords = search_config["keywords"]
        remote_only = search_config["remote_only"]
        locations = search_config["locations"]
        max_applications = search_config["max_applications"]

        self.logger.info(f"üîç –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ ({len(keywords)}): {', '.join(keywords)}")
        if remote_only:
            self.logger.info("üåç –†–µ–∂–∏–º: –¢—ñ–ª—å–∫–∏ –¥–∏—Å—Ç–∞–Ω—Ü—ñ–π–Ω–∞ —Ä–æ–±–æ—Ç–∞")
        else:
            self.logger.info(f"üìç –õ–æ–∫–∞—Ü—ñ—ó: {', '.join(locations)}")
        self.logger.info(f"üéØ –ú–µ—Ç–∞: {max_applications} –≤—ñ–¥–≥—É–∫—ñ–≤")
        self.logger.info("=" * 70)

    async def _search_jobs(self, search_config: dict) -> List[JobListing]:
        """Search for jobs based on configuration

        Args:
            search_config: Search configuration dictionary

        Returns:
            List of job listings
        """
        combined_keyword = " ".join(search_config["keywords"])
        self.logger.info(f"üîé –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –æ–±'—î–¥–Ω–∞–Ω–æ: '{combined_keyword}'")
        self.logger.info(f"üìä –ú–µ—Ç–∞: {search_config['max_applications']} –≤—ñ–¥–≥—É–∫—ñ–≤")
        self.logger.info(f"üìÑ –°–∫–∞–Ω—É–≤–∞–Ω–Ω—è –¥–æ {search_config['max_pages']} —Å—Ç–æ—Ä—ñ–Ω–æ–∫")
        self.logger.info(f"{'='*70}")

        target_jobs = search_config["target_jobs"]
        self.logger.info(
            f"üéØ –¶—ñ–ª—å —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è: {target_jobs} –≤–∞–∫–∞–Ω—Å—ñ–π (x{config.VACANCY_MULTIPLIER} –≤—ñ–¥ –º–µ—Ç–∏ –¥–ª—è –∑–∞–ø–∞—Å—É)"
        )

        if search_config["remote_only"]:
            return await self.scraper.search_jobs(
                keyword=combined_keyword,
                remote=True,
                max_pages=search_config["max_pages"],
                target_jobs=target_jobs,
            )
        else:
            all_jobs = []
            for location in search_config["locations"]:
                jobs_in_loc = await self.scraper.search_jobs(
                    keyword=combined_keyword,
                    location=location,
                    max_pages=search_config["max_pages"],
                    target_jobs=target_jobs,
                )
                all_jobs.extend(jobs_in_loc)
            return all_jobs

    async def _process_jobs(
        self, jobs: List[JobListing], max_applications: int, max_vacancies: int, stats: dict
    ):
        """Process job listings

        Args:
            jobs: List of job listings
            max_applications: Maximum number of applications
            max_vacancies: Maximum number of vacancies to scan
            stats: Statistics dictionary to update
        """
        for idx, job in enumerate(jobs, 1):
            if stats["applied"] >= max_applications:
                self.logger.info(
                    f"üéØ –î–æ—Å—è–≥–Ω—É—Ç–æ –º–µ—Ç—É: {stats['applied']}/{max_applications} –≤—ñ–¥–≥—É–∫—ñ–≤"
                )
                break

            if stats["scanned"] >= max_vacancies:
                self.logger.warning(f"‚ö†Ô∏è –î–æ—Å—è–≥–Ω—É—Ç–æ –ª—ñ–º—ñ—Ç –ø–µ—Ä–µ–≥–ª—è–¥—É: {max_vacancies} –≤–∞–∫–∞–Ω—Å—ñ–π")
                break

            stats["scanned"] += 1
            self._log_job_info(idx, len(jobs), stats["scanned"], job)

            # Analyze job
            should_apply, score, reason = await self.analyze_job(job)

            if self.llm_service.use_llm:
                self.logger.info(f"ü§ñ LLM –æ—Ü—ñ–Ω–∫–∞: {score}/10")
                self.logger.info(f"üí≠ –ü—Ä–∏—á–∏–Ω–∞: {reason}")

            if should_apply:
                await self._apply_to_job(job, stats, max_applications)
            else:
                stats["skipped"] += 1
                self.logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ (–æ—Ü—ñ–Ω–∫–∞ {score} < –º—ñ–Ω—ñ–º—É–º)")

    def _log_job_info(self, idx: int, total: int, scanned: int, job: JobListing):
        """Log job information

        Args:
            idx: Current job index
            total: Total number of jobs
            scanned: Number of jobs scanned
            job: Job listing
        """
        self.logger.info("")
        self.logger.info(f"--- –í–∞–∫–∞–Ω—Å—ñ—è {idx}/{total} (–í—Å—å–æ–≥–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ: {scanned}) ---")
        self.logger.info(f"üìå {job.title}")
        self.logger.info(f"üè¢ {job.company if job.company else '(–Ω–µ –≤–∫–∞–∑–∞–Ω–æ)'}")
        self.logger.info(f"üìç {job.location if job.location else '(–Ω–µ –≤–∫–∞–∑–∞–Ω–æ)'}")
        if job.salary:
            self.logger.info(f"üí∞ {job.salary}")

    async def _apply_to_job(self, job: JobListing, stats: dict, max_applications: int):
        """Apply to a job

        Args:
            job: Job listing
            stats: Statistics dictionary to update
            max_applications: Maximum number of applications
        """
        try:
            success = await self.scraper.apply_to_job(job)
            if success:
                stats["applied"] += 1
                self.logger.info(f"‚úÖ –í—ñ–¥–≥—É–∫–Ω—É–ª–∏—Å—å! ({stats['applied']}/{max_applications})")
            else:
                stats["skipped"] += 1
                self.logger.warning("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—å –≤—ñ–¥–≥—É–∫–Ω—É—Ç–∏—Å—å")

            # Pause between applications
            await asyncio.sleep(2)

        except Exception as e:
            self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–≥—É–∫—É: {e}")
            stats["skipped"] += 1

    def _log_final_stats(self, stats: dict):
        """Log final statistics

        Args:
            stats: Statistics dictionary
        """
        self.logger.info("\n" + "=" * 70)
        self.logger.info("üìä –ü–Ü–î–°–£–ú–ö–ò")
        self.logger.info("=" * 70)
        self.logger.info(f"üîç –í—Å—å–æ–≥–æ –ø–µ—Ä–µ–≥–ª—è–Ω—É—Ç–æ: {stats['scanned']}")
        self.logger.info(f"‚úÖ –í—ñ–¥–≥—É–∫–Ω—É–ª–∏—Å—å: {stats['applied']}")
        self.logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
        self.logger.info("=" * 70)


async def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    # Validate configuration at startup to fail fast
    config.validate()

    setup_logging()

    # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤—ñ–¥–≥—É–∫—ñ–≤ (–º–æ–∂–Ω–∞ –∑ config)
    max_apps = getattr(config, "MAX_APPLICATIONS", 10)

    bot = WorkUABot()
    await bot.run(max_applications=max_apps)


if __name__ == "__main__":
    asyncio.run(main())
